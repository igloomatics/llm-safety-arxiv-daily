{"LLM Safety": {"2602.04294": "|**2026-02-04**|**How Few-shot Demonstrations Affect Prompt-based Defenses Against LLM Jailbreak Attacks**|Yanshu Wang et.al.|[2602.04294](http://arxiv.org/abs/2602.04294)|null|\n", "2602.03792": "|**2026-02-03**|**WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents**|Xilong Wang et.al.|[2602.03792](http://arxiv.org/abs/2602.03792)|null|\n", "2602.03117": "|**2026-02-06**|**AgentDyn: A Dynamic Open-Ended Benchmark for Evaluating Prompt Injection Attacks of Real-World Agent Security System**|Hao Li et.al.|[2602.03117](http://arxiv.org/abs/2602.03117)|null|\n", "2602.03085": "|**2026-02-03**|**The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers**|Blake Bullwinkel et.al.|[2602.03085](http://arxiv.org/abs/2602.03085)|null|\n", "2602.01942": "|**2026-02-02**|**Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework**|Alsharif Abuadbba et.al.|[2602.01942](http://arxiv.org/abs/2602.01942)|null|\n", "2602.01795": "|**2026-02-02**|**RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse**|Mingrui Liu et.al.|[2602.01795](http://arxiv.org/abs/2602.01795)|null|\n", "2602.01587": "|**2026-02-02**|**Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment**|Zehua Cheng et.al.|[2602.01587](http://arxiv.org/abs/2602.01587)|null|\n", "2602.01378": "|**2026-02-01**|**Context Dependence and Reliability in Autoregressive Language Models**|Poushali Sengupta et.al.|[2602.01378](http://arxiv.org/abs/2602.01378)|null|\n", "2602.01129": "|**2026-02-01**|**SMCP: Secure Model Context Protocol**|Xinyi Hou et.al.|[2602.01129](http://arxiv.org/abs/2602.01129)|null|\n", "2602.00750": "|**2026-01-31**|**Bypassing Prompt Injection Detectors through Evasive Injections**|Md Jahedur Rahman et.al.|[2602.00750](http://arxiv.org/abs/2602.00750)|null|\n", "2602.05746": "|**2026-02-05**|**Learning to Inject: Automated Prompt Injection via Reinforcement Learning**|Xin Chen et.al.|[2602.05746](http://arxiv.org/abs/2602.05746)|null|\n", "2602.05484": "|**2026-02-05**|**Clouding the Mirror: Stealthy Prompt Injection Attacks Targeting LLM-based Phishing Detection**|Takashi Koide et.al.|[2602.05484](http://arxiv.org/abs/2602.05484)|null|\n", "2602.05066": "|**2026-02-04**|**Bypassing AI Control Protocols via Agent-as-a-Proxy Attacks**|Jafar Isbarov et.al.|[2602.05066](http://arxiv.org/abs/2602.05066)|null|\n", "2602.06440": "|**2026-02-06**|**TrailBlazer: History-Guided Reinforcement Learning for Black-Box LLM Jailbreaking**|Sung-Hoon Yoon et.al.|[2602.06440](http://arxiv.org/abs/2602.06440)|null|\n", "2602.06268": "|**2026-02-06**|**MPIB: A Benchmark for Medical Prompt Injection Attacks and Clinical Safety in LLMs**|Junhyeok Lee et.al.|[2602.06268](http://arxiv.org/abs/2602.06268)|null|\n", "2602.07398": "|**2026-02-07**|**AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management**|Ruoyao Wen et.al.|[2602.07398](http://arxiv.org/abs/2602.07398)|null|\n", "2602.07381": "|**2026-02-07**|**When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified**|Gautam Siddharth Kashyap et.al.|[2602.07381](http://arxiv.org/abs/2602.07381)|null|\n", "2602.07104": "|**2026-02-06**|**Extended to Reality: Prompt Injection in 3D Environments**|Zhuoheng Li et.al.|[2602.07104](http://arxiv.org/abs/2602.07104)|null|\n", "2602.08995": "|**2026-02-09**|**When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents**|Yuting Ning et.al.|[2602.08995](http://arxiv.org/abs/2602.08995)|null|\n", "2602.08062": "|**2026-02-08**|**Efficient and Adaptable Detection of Malicious LLM Prompts via Bootstrap Aggregation**|Shayan Ali Hassan et.al.|[2602.08062](http://arxiv.org/abs/2602.08062)|null|\n", "2602.07918": "|**2026-02-08**|**CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution**|Minbeom Kim et.al.|[2602.07918](http://arxiv.org/abs/2602.07918)|null|\n", "2602.09433": "|**2026-02-10**|**Autonomous Action Runtime Management(AARM):A System Specification for Securing AI-Driven Actions at Runtime**|Herman Errico et.al.|[2602.09433](http://arxiv.org/abs/2602.09433)|null|\n", "2602.09222": "|**2026-02-09**|**MUZZLE: Adaptive Agentic Red-Teaming of Web Agents Against Indirect Prompt Injection Attacks**|Georgios Syros et.al.|[2602.09222](http://arxiv.org/abs/2602.09222)|null|\n", "2602.10915": "|**2026-02-13**|**Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System**|Zhenhua Zou et.al.|[2602.10915](http://arxiv.org/abs/2602.10915)|null|\n", "2602.10498": "|**2026-02-11**|**When Skills Lie: Hidden-Comment Injection in LLM Agents**|Qianli Wang et.al.|[2602.10498](http://arxiv.org/abs/2602.10498)|null|\n", "2602.10481": "|**2026-02-11**|**Protecting Context and Prompts: Deterministic Security for Non-Deterministic AI**|Mohan Rajagopalan et.al.|[2602.10481](http://arxiv.org/abs/2602.10481)|null|\n", "2602.10453": "|**2026-02-11**|**The Landscape of Prompt Injection Threats in LLM Agents: From Taxonomy to Analysis**|Peiran Wang et.al.|[2602.10453](http://arxiv.org/abs/2602.10453)|null|\n", "2602.11416": "|**2026-02-11**|**Optimizing Agent Planning for Security and Autonomy**|Aashish Kolluri et.al.|[2602.11416](http://arxiv.org/abs/2602.11416)|null|\n", "2602.11247": "|**2026-02-11**|**Peak + Accumulation: A Proxy-Level Scoring Formula for Multi-Turn LLM Attack Detection**|J Alex Corll et.al.|[2602.11247](http://arxiv.org/abs/2602.11247)|null|\n", "2602.12418": "|**2026-02-12**|**Sparse Autoencoders are Capable LLM Jailbreak Mitigators**|Yannick Assogba et.al.|[2602.12418](http://arxiv.org/abs/2602.12418)|null|\n", "2602.14161": "|**2026-02-15**|**When Benchmarks Lie: Evaluating Malicious Prompt Classifiers Under True Distribution Shift**|Max Fomin et.al.|[2602.14161](http://arxiv.org/abs/2602.14161)|null|\n", "2602.13597": "|**2026-02-14**|**AlignSentinel: Alignment-Aware Detection of Prompt Injection Attacks**|Yuqi Jia et.al.|[2602.13597](http://arxiv.org/abs/2602.13597)|null|\n", "2602.13477": "|**2026-02-13**|**OMNI-LEAK: Orchestrator Multi-Agent Network Induced Data Leakage**|Akshat Naik et.al.|[2602.13477](http://arxiv.org/abs/2602.13477)|null|\n", "2602.14211": "|**2026-02-15**|**SkillJect: Automating Stealthy Skill-Based Prompt Injection for Coding Agents with Trace-Driven Closed-Loop Refinement**|Xiaojun Jia et.al.|[2602.14211](http://arxiv.org/abs/2602.14211)|null|\n"}, "LLM Alignment": {"2602.04369": "|**2026-02-04**|**Multi-scale hypergraph meets LLMs: Aligning large language models for time series analysis**|Zongjiang Shang et.al.|[2602.04369](http://arxiv.org/abs/2602.04369)|null|\n", "2602.04197": "|**2026-02-04**|**From Helpfulness to Toxic Proactivity: Diagnosing Behavioral Misalignment in LLM Agents**|Xinyue Wang et.al.|[2602.04197](http://arxiv.org/abs/2602.04197)|null|\n", "2602.02742": "|**2026-02-11**|**Entropy-Guided Dynamic Tokens for Graph-LLM Alignment in Molecular Understanding**|Zihao Jing et.al.|[2602.02742](http://arxiv.org/abs/2602.02742)|null|\n", "2602.02495": "|**2026-02-09**|**Reward-free Alignment for Conflicting Objectives**|Peter L. Chen et.al.|[2602.02495](http://arxiv.org/abs/2602.02495)|null|\n", "2602.01581": "|**2026-02-02**|**Nearly Optimal Active Preference Learning and Its Application to LLM Alignment**|Yao Zhao et.al.|[2602.01581](http://arxiv.org/abs/2602.01581)|null|\n", "2601.22329": "|**2026-01-29**|**Sparks of Rationality: Do Reasoning LLMs Align with Human Judgment and Choice?**|Ala N. Tak et.al.|[2601.22329](http://arxiv.org/abs/2601.22329)|null|\n", "2601.18731": "|**2026-01-26**|**One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment**|Hongru Cai et.al.|[2601.18731](http://arxiv.org/abs/2601.18731)|null|\n", "2601.18533": "|**2026-01-26**|**From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation**|Yuxin Jiang et.al.|[2601.18533](http://arxiv.org/abs/2601.18533)|null|\n", "2601.17329": "|**2026-01-24**|**Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment**|Tiejin Chen et.al.|[2601.17329](http://arxiv.org/abs/2601.17329)|null|\n", "2601.13669": "|**2026-01-20**|**CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks**|Jiayu Lin et.al.|[2601.13669](http://arxiv.org/abs/2601.13669)|null|\n", "2602.04909": "|**2026-02-10**|**Learning Where It Matters: Geometric Anchoring for Robust Preference Alignment**|Youngjae Cho et.al.|[2602.04909](http://arxiv.org/abs/2602.04909)|null|\n", "2602.05946": "|**2026-02-09**|**f-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment**|Rajdeep Haldar et.al.|[2602.05946](http://arxiv.org/abs/2602.05946)|null|\n", "2602.07799": "|**2026-02-08**|**Fairness Aware Reward Optimization**|Ching Lam Choi et.al.|[2602.07799](http://arxiv.org/abs/2602.07799)|null|\n", "2602.07539": "|**2026-02-07**|**Training-Driven Representational Geometry Modularization Predicts Brain Alignment in Language Models**|Yixuan Liu et.al.|[2602.07539](http://arxiv.org/abs/2602.07539)|null|\n", "2602.11328": "|**2026-02-11**|**Evaluating Alignment of Behavioral Dispositions in LLMs**|Amir Taubenfeld et.al.|[2602.11328](http://arxiv.org/abs/2602.11328)|null|\n", "2602.12180": "|**2026-02-12**|**How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics**|Yurong Chen et.al.|[2602.12180](http://arxiv.org/abs/2602.12180)|null|\n", "2602.12134": "|**2026-02-12**|**Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment**|Jiajun Chen et.al.|[2602.12134](http://arxiv.org/abs/2602.12134)|null|\n", "2602.13575": "|**2026-02-14**|**Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment**|Jing Zhao et.al.|[2602.13575](http://arxiv.org/abs/2602.13575)|null|\n", "2602.13562": "|**2026-02-14**|**Mitigating the Safety-utility Trade-off in LLM Alignment via Adaptive Safe Context Learning**|Yanbo Wang et.al.|[2602.13562](http://arxiv.org/abs/2602.13562)|null|\n", "2602.14338": "|**2026-02-15**|**Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning**|Zhi Zhang et.al.|[2602.14338](http://arxiv.org/abs/2602.14338)|null|\n", "2602.15338": "|**2026-02-17**|**Discovering Implicit Large Language Model Alignment Objectives**|Edward Chen et.al.|[2602.15338](http://arxiv.org/abs/2602.15338)|null|\n"}, "LLM Hallucination": {"2602.04072": "|**2026-02-03**|**Data Verification is the Future of Quantum Computing Copilots**|Junhao Song et.al.|[2602.04072](http://arxiv.org/abs/2602.04072)|null|\n", "2602.03652": "|**2026-02-03**|**RAGTurk: Best Practices for Retrieval Augmented Generation in Turkish**|S\u00fcha Ka\u011fan K\u00f6se et.al.|[2602.03652](http://arxiv.org/abs/2602.03652)|null|\n", "2601.21410": "|**2026-02-04**|**Statsformer: Validated Ensemble Learning with LLM-Derived Semantic Priors**|Erica Zhang et.al.|[2601.21410](http://arxiv.org/abs/2601.21410)|null|\n", "2601.21278": "|**2026-01-29**|**GeoRC: A Benchmark for Geolocation Reasoning Chains**|Mohit Talreja et.al.|[2601.21278](http://arxiv.org/abs/2601.21278)|null|\n", "2601.18753": "|**2026-01-26**|**HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs**|Xinyue Zeng et.al.|[2601.18753](http://arxiv.org/abs/2601.18753)|null|\n", "2601.16766": "|**2026-01-23**|**Do LLM hallucination detectors suffer from low-resource effect?**|Debtanu Datta et.al.|[2601.16766](http://arxiv.org/abs/2601.16766)|null|\n", "2601.13702": "|**2026-01-20**|**IGAA: Intent-Driven General Agentic AI for Edge Services Scheduling using Generative Meta Learning**|Yan Sun et.al.|[2601.13702](http://arxiv.org/abs/2601.13702)|null|\n", "2601.12019": "|**2026-01-17**|**Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning**|Chaowei Zhang et.al.|[2601.12019](http://arxiv.org/abs/2601.12019)|null|\n", "2601.10467": "|**2026-01-20**|**AI Sycophancy: How Users Flag and Respond**|Kazi Noshin et.al.|[2601.10467](http://arxiv.org/abs/2601.10467)|null|\n", "2601.08036": "|**2026-01-12**|**Automating API Documentation from Crowdsourced Knowledge**|Bonan Kou et.al.|[2601.08036](http://arxiv.org/abs/2601.08036)|null|\n", "2602.05932": "|**2026-02-05**|**Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions**|L\u00e9o Labat et.al.|[2602.05932](http://arxiv.org/abs/2602.05932)|null|\n", "2602.12083": "|**2026-02-12**|**Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication**|Antonin Sulc et.al.|[2602.12083](http://arxiv.org/abs/2602.12083)|null|\n", "2602.11167": "|**2026-01-18**|**Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering**|Nathan Mao et.al.|[2602.11167](http://arxiv.org/abs/2602.11167)|null|\n", "2602.14259": "|**2026-02-15**|**Detecting LLM Hallucinations via Embedding Cluster Geometry: A Three-Type Taxonomy with Measurable Signatures**|Matic Korun et.al.|[2602.14259](http://arxiv.org/abs/2602.14259)|null|\n"}, "LLM Privacy": {"2601.18777": "|**2026-01-26**|**PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation**|Abhishek Divekar et.al.|[2601.18777](http://arxiv.org/abs/2601.18777)|null|\n", "2601.15550": "|**2026-01-28**|**Common to Whom? Regional Cultural Commonsense and LLM Bias in India**|Sangmitra Madhusudan et.al.|[2601.15550](http://arxiv.org/abs/2601.15550)|null|\n", "2601.05403": "|**2026-01-08**|**Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection**|Zhiwei Liu et.al.|[2601.05403](http://arxiv.org/abs/2601.05403)|null|\n", "2512.16532": "|**2025-12-18**|**From Personalization to Prejudice: Bias and Discrimination in Memory-Enhanced AI Agents for Recruitment**|Himanshu Gharat et.al.|[2512.16532](http://arxiv.org/abs/2512.16532)|null|\n", "2512.14600": "|**2025-12-16**|**PerProb: Indirectly Evaluating Memorization in Large Language Models**|Yihan Liao et.al.|[2512.14600](http://arxiv.org/abs/2512.14600)|null|\n", "2511.21758": "|**2025-11-24**|**A Longitudinal Measurement of Privacy Policy Evolution for Large Language Models**|Zhen Tao et.al.|[2511.21758](http://arxiv.org/abs/2511.21758)|null|\n", "2511.00192": "|**2025-10-31**|**EL-MIA: Quantifying Membership Inference Risks of Sensitive Entities in LLMs**|Ali Satvaty et.al.|[2511.00192](http://arxiv.org/abs/2511.00192)|null|\n", "2510.23921": "|**2025-10-27**|**Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation**|Kaveh Eskandari Miandoab et.al.|[2510.23921](http://arxiv.org/abs/2510.23921)|null|\n", "2510.18556": "|**2025-10-21**|**Building Trust in Clinical LLMs: Bias Analysis and Dataset Transparency**|Svetlana Maslenkova et.al.|[2510.18556](http://arxiv.org/abs/2510.18556)|null|\n", "2510.10805": "|**2025-10-12**|**Therapeutic AI and the Hidden Risks of Over-Disclosure: An Embedded AI-Literacy Framework for Mental Health Privacy**|Soraya S. Anvari et.al.|[2510.10805](http://arxiv.org/abs/2510.10805)|null|\n", "2602.10833": "|**2026-02-11**|**Training-Induced Bias Toward LLM-Generated Content in Dense Retrieval**|William Xion et.al.|[2602.10833](http://arxiv.org/abs/2602.10833)|null|\n", "2602.14233": "|**2026-02-15**|**Evaluating LLMs in Finance Requires Explicit Bias Consideration**|Yaxuan Kong et.al.|[2602.14233](http://arxiv.org/abs/2602.14233)|null|\n"}}